---
title:  "LangGraph(Basic Stream)"
categories: LangChain
tag: [theory, AI, LLM, LangChain, LangGraph, Agent]
toc: true
author_profile: false
sidebar:
    nav: "docs"
use_math: true
excerpt: Prompt
comments: true
date: 2024-12-23
toc_sticky: true
---
하기의 내용은 <a href="https://wikidocs.net/233801" target="_blank">LangChain 노트</a> 기반으로 작성했습니다.
# Stream
Stream 메서드는 LangGraph에서 제공하는 기능입니다. 이 Stream 메서드를 통해 Graph구조에서 어떤 input과 어떤 output을 내뱉어내는지를 출력을 통해 직접적으로 확인을 할 수 있습니다. 정확한 설명 및 더 다양한 메서드들에 대한 설명명은 <a href="https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.graph.CompiledGraph.stream" target="_blank">LangGraph Method</a>에서 확인할 수 있습니다.   
우선 Stream 메서드에 대해 살펴보면 하기와 같은 argument들을 가집니다.   

```python
stream(input: Union[dict[str, Any], Any], 
config: Optional[RunnableConfig] = None, 
*,
stream_mode: Optional[Union[StreamMode, list[StreamMode]]] = None, 
output_keys: Optional[Union[str, Sequence[str]]] = None,
interrupt_before: Optional[Union[All, Sequence[str]]] = None, 
interrupt_after: Optional[Union[All, Sequence[str]]] = None, 
debug: Optional[bool] = None, subgraphs: bool = False)
-> Iterator[Union[dict[str, Any], Any]]
```
하나씩 살펴보겠습니다.   
- input : 그래프에 대한 입력
- config : 실행을 위한 Config 정보
- stream_mode : 출력 스트리밍 모드(Option은 values, updates, debug 존재)
    - values : 각 단계마다 상태의 현재 값을 출력
    - updates : 각 단계마다 상태의 업데이트만을 출력합니다. 출력은 노드 이름을 키로 하고 업데이트된 값을 값으로 가지는 dict(사전) 형태
    - debug : 각 단계에 대한 디버그 이벤트를 출력
- output_keys : 스트리밍할 key
- interrupt_before : 실행 전에 중단할 Node 
- interrupt_after : 실행 후 중단할 Node
- debug : debug깅 정보 출력 여부
- subgraphs : subgraph 스트리밍 여부
- Iterator : 그래프의 각 단계 출력(출력 방법은 stream_mode를 따름)

## Default Stream
가장 default 방법으로 한번 stream하는 코드를 살펴보겠습니다.   

```python
from langchain_core.runnables import RunnableConfig

# 질문
question = "2024년 노벨 문학상 관련 뉴스를 알려주세요."

# 초기 입력 상태를 정의
input = State(dummy_data="테스트 문자열", messages=[("user", question)])

# config 설정
config = RunnableConfig(
    recursion_limit=10,  # 최대 10개의 노드까지 방문. 그 이상은 RecursionError 발생
    configurable={"thread_id": "1"},  # 스레드 ID 설정
    tags=["my-tag"],  # Tag
)

for event in graph.stream(input=input, config=config):
    for key, value in event.items():
        print(f"\n[ {key} ]\n")
        # value 에 messages 가 존재하는 경우
        if "messages" in value:
            # 가장 최근 메시지 1개만 출력합니다.
            value["messages"][-1].pretty_print()
```

상기의 코드에서 event.items()에 존재하는 key는 어떤 Node인지를 가르키며, value안에 messages가 있다면 가장 최근 message 1개를 출력합니다.   

## output_keys
이번에는 output_keys를 통해 스트리밍할 key를 지정하겠습니다.   
하기의 코드를 통해 graph에 존재하는 state정보들을 모두 확인할 수 있습니다. 즉, node, edge가 어떤게 존재하는지를 확인할 수 있습니다.   
```python
print(list(graph.channels.keys()))
```

상기의 코드와 동일하게 messages의 key에 대한 스트리밍만 출력해보겠습니다.    
```python
for event in graph.stream(
    input=input,
    config=config,
    output_keys=["messages"],  # messages 만 출력
):
    for key, value in event.items():
        # messages 가 존재하는 경우
        if value and "messages" in value:
            # key 는 노드 이름
            print(f"\n[ {key} ]\n")
            # messages 의 마지막 요소의 content 를 출력합니다.
            print(value["messages"][-1].content)
```

output_keys에 messages key만 출력하게 지정한 것 입니다. 그럼 State Class에 정의한 messages에 대한 정보만 스트리밍을 할 수 있게됩니다.   

## stream_mode
stream_mode에는 크게 values, updates, debug 3가지가 존재한다고 말씀드렸습니다. 이는 출력 모드를 지정하는 것입니다.   
만약 stream_mode = 'values'라면 현재 상태의 값만을 출력합니다.   
```python
# 질문
question = "2024년 노벨 문학상 관련 뉴스를 알려주세요."

# 초기 입력 State 를 정의
input = State(dummy_data="테스트 문자열", messages=[("user", question)])

# config 설정
config = RunnableConfig(
    recursion_limit=10,  # 최대 10개의 노드까지 방문. 그 이상은 RecursionError 발생
    configurable={"thread_id": "1"},  # 스레드 ID 설정
    tags=["my-rag"],  # Tag
)

# values 모드로 스트리밍 출력
for event in graph.stream(
    input=input,
    stream_mode="values",  # 기본값
):
    for key, value in event.items():
        # key 는 state 의 key 값
        print(f"\n[ {key} ]\n")
        if key == "messages":
            print(f"메시지 개수: {len(value)}")
            print(value[-1])
    print("===" * 10, " 단계 ", "===" * 10)
```

상기의 코드에서 처음 question이 state에 담겨 1개, 그 다음 tool Node로 넘어가기전 state가 chatbot Node로 들어가니 2개, 이제 ToolNode로 들어가니 3개 이런식으로 현재 message의 개수가 출력되게 됩니다.   
<br>
그럼 이번에는 stream_mode = 'updates'에 대해 살펴보겠습니다.   

```python
# updates 모드로 스트리밍 출력
for event in graph.stream(
    input=input,
    stream_mode="updates",  # 기본값
):
    for key, value in event.items():
        # key 는 노드 이름
        print(f"\n[ {key} ]\n")

        # value 는 노드의 출력값
        print(value.keys())

        # value 에는 state 가 dict 형태로 저장(values 의 key 값)
        if "messages" in value:
            print(f"메시지 개수: {len(value['messages'])}")
            print(value["messages"])
    print("===" * 10, " 단계 ", "===" * 10)
```
상기의 코드를 실행시켜보시면, 시작시 chatbotNode에 넘겨준 State는 2개인 messages와 dummy_data가 있습니다. 여기서 이제 ToolNode로는 messages 정보만 넘겨주게되니, 이 messages를 통해 Tool Call을 하여 정보를 얻어옵니다. 그 후, 다시 chatbot Node로 messages 정보를 넘겨주는 작업이 수행되는 것을 직관적으로 확인할 수 있습니다. 즉, 이렇듯 업데이트되는 정보만을 확인할 수 있습니다. 따라서, stream_mode = 'values'과 다르게 모든 메세지가 1개인 것을 확인할 수 있습니다.   

## interrupt
interrupt_before과 interrupt_after이 존재한다고 말씀드렸습니다. interrupt_before은 지정된 Node이전에 스트리밍을 중단, interrupt_after는 지정된 Node 이후에 스트리밍 중단을 가르킵니다. 그럼 우선 interrupt_before을 먼저 지정해보겠습니다.   
```python
for event in graph.stream(
    input=input,
    config=config,
    stream_mode="updates",  # 기본값
    interrupt_before=["tools"],  # tools 노드 이전에 스트리밍 중단
):
    for key, value in event.items():
        # key 는 노드 이름
        print(f"\n[{key}]\n")

        # value 는 노드의 출력값
        if isinstance(value, dict):
            print(value.keys())
            if "messages" in value:
                print(value["messages"])

        # value 에는 state 가 dict 형태로 저장(values 의 key 값)
        if "messages" in value:
            print(f"메시지 개수: {len(value['messages'])}")
    print("===" * 10, " 단계 ", "===" * 10)
```

상기의 코드를 실행해보시면, tools Node가 call하기전에 streaming이 중단되는 것을 확인할 수 있습니다.    
그럼 반대로 interrupt_after=["tools"]을 지정해주면 toolNode 호출 후 streaming이 중단될 것이라고 예측하실 수 있으실겁니다.   

# Human 개입
실제로 agent에게 모든 작업을 맡길 수 있다면 참 좋겠지만, 이를 완전히 신뢰하기에는 아직 부족합니다. 즉, 어떤 작업에 대해 agent가 의도대로 잘 동작하고 있는지를 확인하고 싶은 경우가 존재할 수 있습니다. 이런 경우 **사람의 승인을 요구**하고 싶을 수도 있습니다. 그럼 특정 Node에 들어가기전에 확인하는 interrupt_before기능을 이용하여 도구를 중단하는 방법을 살펴보겠습니다.    
```python
from langchain_teddynote.messages import pretty_print_messages
from langchain_core.runnables import RunnableConfig

# 질문
question = "AI 관련 최신 뉴스를 알려주세요."

# 초기 입력 State 를 정의
input = State(messages=[("user", question)])

# config 설정
config = RunnableConfig(
    recursion_limit=10,  # 최대 10개의 노드까지 방문. 그 이상은 RecursionError 발생
    configurable={"thread_id": "1"},  # 스레드 ID 설정
    tags=["my-rag"],  # Tag
)

for event in graph.stream(
    input=input,
    config=config,
    stream_mode="values",
    interrupt_before=["tools"],  # tools 실행 전 interrupt(tools 노드 실행 전 중단)
):
    for key, value in event.items():
        # key 는 노드 이름
        print(f"\n[{key}]\n")

        # value 는 노드의 출력값
        # print(value)
        pretty_print_messages(value)

        # value 에는 state 가 dict 형태로 저장(values 의 key 값)
        if "messages" in value:
            print(f"메시지 개수: {len(value['messages'])}")
```

상기의 코드는 toolNode로 가기전에 멈추게됩니다. 이를 graph.get_state(config)에 snapshot이 저장되어 마지막 호출을 확인해볼 수 있습니다.   
<br>
만약 이렇게 중단된 후, 다시 Graph를 이어서 진행시키고 싶다면 **stream 입력에 None**을 넣어주면 됩니다. 그럼 이전 멈춘 toolNode부터 다시 Graph를 타기시작하게됩니다. 이런식으로 interrupt를 통해 사람이 개입할 수 있는 작업을 정의해주고 직접 사람이 감독이나 수정을 수행할 수 있습니다.   
또는 만약 상태 기록을 가져오는 방법도 존재합니다. 상태 기록을 통해 원하는 상태를 지정하여 해당 지점에서 다시 Graph를 시작할 수도 있습니다.   

```python
to_replay = None

# 상태 기록 가져오기
for state in graph.get_state_history(config):
    # 메시지 수 및 다음 상태 출력
    print("메시지 수: ", len(state.values["messages"]), "다음 노드: ", state.next)
    print("-" * 80)
    # 특정 상태 선택 기준: 채팅 메시지 수
    if len(state.values["messages"]) == 3:
        to_replay = state
``` 

# State Back(중간 지점 되돌리기)
방금전까지 사람의 개입할 수 있는 방법에 대해 대략적으로 알아보았습니다. 그럼 이번에는 직접 개입하여 이전단계로 되돌리는 작업을 수행해보도록 하겠습니다. 
우선 TavilySearch에서 나온 검색 결과를 사람이 원하는 검색결과로 바꾸는 과정에 대해 살펴보겠습니다.   

```python
from langchain_core.messages import AIMessage, ToolMessage

# 사람의 원하는 검색색
modified_search_result = """[수정된 웹 검색 결과] 
LangGraph는 상태 기반의 다중 액터 애플리케이션을 LLM을 활용해 구축할 수 있도록 지원합니다.
LangGraph는 사이클 흐름, 제어 가능성, 지속성, 클라우드 배포 기능을 제공하는 오픈 소스 라이브러리입니다.

자세한 튜토리얼은 [LangGraph 튜토리얼](https://langchain-ai.github.io/langgraph/tutorials/) 과
테디노트의 [랭체인 한국어 튜토리얼](https://wikidocs.net/233785) 을 참고하세요."""

# 그래프 상태 스냅샷 생성
snapshot = graph.get_state(config)

# 가장 최근 메시지 추출
last_message = snapshot.values["messages"][-1]

# 메시지 출력
last_message.pretty_print()

tool_call_id = last_message.tool_calls[0]["id"]

new_messages = [
    # LLM API의 도구 호출과 일치하는 ToolMessage 필요
    ToolMessage(
        content=modified_search_result,
        tool_call_id=tool_call_id,
    ),
    # LLM의 응답에 직접적으로 내용 추가
    # AIMessage(content=modified_search_result),
]
new_messages[-1].pretty_print()
```

toolNode호출전에 interrupt가되니 마지막 message는 ToolNode의 TavilySearch의 검색결과가 됩니다. 이 snapshot의 tool_id를 얻어낸 후 tool_id에 맞게 ToolMessage를 상기의 코드와같이 변경해주면됩니다.   
이제 StateGraph에 해당 Message값으로 변경해주는 update_state 메서드를 호출하여 변경해주면 됩니다.   

```python
graph.update_state(
    # 업데이트할 상태 지정
    config,
    # 제공할 업데이트된 값. `State`의 메시지는 "추가 전용"으로 기존 상태에 추가됨
    {"messages": new_messages},
    as_node="tools",
)
```
tools라는 Node의 Message정보를 사용자가 원하는 검색의 messages로 변경이되게합니다. 그 후 이어서 input을 None으로 똑같이 Graph를 호출해주면 변경된 검색 결과를 기반으로 agent는 답변을 하게 됩니다.