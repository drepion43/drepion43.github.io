---
title:  "LangGraph(CRAG)"
categories: LangChain
tag: [theory, AI, LLM, LangChain, LangGraph, RAG]
toc: true
author_profile: false
sidebar:
    nav: "docs"
use_math: true
excerpt: Agent
comments: true
date: 2025-04-10
toc_sticky: true
---
í•˜ê¸°ì˜ ë‚´ìš©ì€ <a href="https://wikidocs.net/233801" target="_blank">LangChain ë…¸íŠ¸</a> ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±í–ˆìŠµë‹ˆë‹¤.

# Corrective RAG
ì´ë²ˆì ˆì—ì„œëŠ” **Corrective RAG**ì˜ ì „ëµì„ ì´ìš©í•˜ì—¬ RAGê¸°ë°˜ ì‹œìŠ¤í…œì„ ê°œì„ í•´ë³´ê² ìŠµë‹ˆë‹¤. **Corrective RAG**ëŠ” ì´ì „ <a href="https://drepion43.github.io/langchain/langgraph12/#graph-compile" target="_blank">Adaptive RAG</a>ì—ì„œ ë‹¤ë¤˜ë˜ ë‚´ìš©ì…ë‹ˆë‹¤. í•œë²ˆ ë” ìì„¸í•˜ê²Œ ì‚´í´ë³´ìë©´ **Corrective RAG**ëŠ” ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì— ëŒ€í•´ ìê¸° ë°˜ì„±(self-reflection) ë° ìê¸° í‰ê°€(self-evaluation)ì„ í†µí•´, ê²€ìƒ‰-ìƒì„±(RAG)ë¥¼ ë” ì •êµí•˜ê²Œ/ì •í™•í•˜ê²Œ ë‹¤ë£° ìˆ˜ ìˆë„ë¡ ë„ì™€ì¤ë‹ˆë‹¤. ì¦‰, **ê²€ìƒ‰ ê³¼ì •ì—ì„œ ì°¾ì•„ì˜¨ ë¬¸ì„œë¥¼ í‰ê°€í•˜ê³ , ì§€ì‹ì„ ì •ì œ(refine) í•˜ëŠ” ë‹¨ê³„ë¥¼ ì¶”ê°€í•œ ë°©ë²•ë¡ **ì…ë‹ˆë‹¤.    
<br>
ë” ìì„¸í•œ ë‚´ìš©ì„ ì•Œì•„ë³´ê³  ì‹¶ìœ¼ì‹  ë¶„ì€ í•˜ê¸°ì˜ ë…¼ë¬¸ì„ í•œë²ˆ ë¦¬ë”©í•´ë³´ì‹œëŠ” ê²ƒë„ ì¶”ì²œë“œë¦½ë‹ˆë‹¤.   
<a href="https://arxiv.org/pdf/2401.15884" target="_blank">Corrective RAG</a>   
í•˜ê¸°ì˜ ë‚´ìš©ì„ ê°„ëµí•˜ê²Œ ì„¤ëª…í•´ë³´ê² ìŠµë‹ˆë‹¤.    
â‘  ê²€ìƒ‰ëœ ë¬¸ì„œ ì¤‘ í•˜ë‚˜ ì´ìƒì´ ì‚¬ì „ ì •ì˜ëœ ê´€ë ¨ì„± ì„ê³„ê°’(retrieval validation score) ì„ ì´ˆê³¼í•˜ë©´ ìƒì„± ë‹¨ê³„ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.   
â‘¡ ìƒì„± ì „ì— ì§€ì‹ ì •ì œ ë‹¨ê³„ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.   
â‘¢ ë¬¸ì„œë¥¼ "knowledge strips"ë¡œ ì„¸ë¶„í™”í•©ë‹ˆë‹¤.(ì—¬ê¸°ì„œ, ë¬¸ì„œ ê²€ìƒ‰ ê²°ê³¼ìˆ˜, kë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.)   
â‘£ ê° ì§€ì‹ ìŠ¤íŠ¸ë¦½ì„ í‰ê°€í•˜ê³  ê´€ë ¨ì„± ì—¬ë¶€ë¥¼ score ë¡œ í‰ê°€í•©ë‹ˆë‹¤. (ì—¬ê¸°ì„œëŠ” ë¬¸ì„œ chunk ë‹¨ìœ„ë¡œ í‰ê°€í•©ë‹ˆë‹¤.)     
â‘¤ ëª¨ë“  ë¬¸ì„œê°€ ê´€ë ¨ì„± ì„ê³„ê°’ ì´í•˜ì´ê±°ë‚˜ í‰ê°€ ê²°ê³¼ ì‹ ë¢°ë„ê°€ ë‚®ì„ ê²½ìš°, ì¶”ê°€ ë°ì´í„° ì†ŒìŠ¤(ì˜ˆ: ì›¹ ê²€ìƒ‰)ë¡œ ë³´ê°•í•©ë‹ˆë‹¤.   
â‘¥ ì›¹ ê²€ìƒ‰ì„ í†µí•œ ë³´ê°• ì‹œ, ì¿¼ë¦¬ ì¬ì‘ì„±(Query-Rewrite) ì„ í†µí•´ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìµœì í™”í•©ë‹ˆë‹¤.   

<br>
ê·¸ëŸ¼ ì´ë²ˆì ˆì—ì„œëŠ” â‘¡ì¸ **ì§€ì‹ ì •ì œ ë‹¨ê³„**ëŠ” ìƒëµí•˜ë©°, í•„ìš”ì‹œ ë…¸ë“œë¡œ ì¶”ê°€í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ì„¤ê³„í•´ë³´ê² ìŠµë‹ˆë‹¤.   
ë˜í•œ, â‘¤ê³¼ ê°™ì´ ê´€ë ¨ ìˆëŠ” ë¬¸ì„œê°€ í•˜ë‚˜ë„ ì—†ë‹¤ë©´ **ì›¹ ê²€ìƒ‰**ì„ ì´ìš©í•˜ì—¬ ê²€ìƒ‰ì„ ë³´ì™„í•˜ë„ë¡ ì„¤ê³„í•˜ê² ìŠµë‹ˆë‹¤. ê·¸ í›„ ì¿¼ë¦¬ ì¬ì‘ì„±(Query Rewrite)ë¥¼ ì´ìš©í•´ ê²€ìƒ‰ ìµœì í™”ë¥¼ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤.   

<br>
í¬ê²Œ í•˜ê¸°ì˜ ë‹¨ê³„ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.   
- **Retrieval Grader**: ê²€ìƒ‰ëœ ë¬¸ì„œì˜ ê´€ë ¨ì„±ì„ í‰ê°€
- **Generate**: LLMì„ í†µí•œ ë‹µë³€ ìƒì„±
- **Question Re-writer**: ì§ˆë¬¸ ì¬ì‘ì„±ì„ í†µí•œ ê²€ìƒ‰ ì§ˆì˜ ìµœì í™”
- **Web Search Tool**: Tavily Searchë¥¼ í†µí•œ ì›¹ ê²€ìƒ‰ í™œìš©
- **Create Graph**: LangGraphë¥¼ í†µí•œ CRAG ì „ëµ ê·¸ë˜í”„ ìƒì„±
- **Use the graph**: ìƒì„±ëœ ê·¸ë˜í”„ë¥¼ í™œìš©í•˜ëŠ” ë°©ë²•

## Generate & Retrieval Grader
ê¸°ì¡´ì— ë°°ì› ë˜ Retrievalë¥¼ ìƒì„±í•˜ê³  ì´ Retrievalê°€ ê°€ì ¸ì˜¨ ë¬¸ì„œê°€ ì§ˆë¬¸ê³¼ í‰ê°€í•˜ëŠ” Relevence Checkë¥¼ êµ¬í˜„í•˜ê² ìŠµë‹ˆë‹¤.   
```python
class RAGPDFChain:
    def __init__(self, pdf, llm):
        self.llm = llm
        self.pdf = pdf
    
    def create_retriever(self, 
                         embeddings: object = OpenAIEmbeddings(model="text-embedding-ada-002")):
        loader = PyPDFLoader(self.pdf)

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
        split_docs = loader.load_and_split(text_splitter)
        vector = FAISS.from_documents(split_docs, embeddings)
        retriever = vector.as_retriever()
        return retriever

        
    def format_docs(self, docs):
        """ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…"""
        context = ""
        for doc in docs:
            context += doc.page_content
            context += '\n'
        return context
            

    def invoke(self, inputs):
        question = inputs.get("question", "")
        context = inputs.get("context", [])
        if isinstance(context, list):
            context = self.format_docs(context)
        history = inputs.get("chat_history", [])
        history = " ".join(history)
        
        template = """
        ë‹¤ìŒ ì •ë³´ëŠ” ì´ì „ ëŒ€í™”ì— ëŒ€í•œ ë‚´ìš©ì…ë‹ˆë‹¤.
        {chat_history}
        
        ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”:
        {context}

        ì§ˆë¬¸: {question}
        
        ì£¼ì–´ì§„ ì§ˆë¬¸ì—ë§Œ ë‹µë³€í•˜ì„¸ìš”. ë¬¸ì¥ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
        ë‹µë³€:
        """
        prompt = PromptTemplate.from_template(template)
        
        rag_chain = (
            prompt
            | self.llm
            | StrOutputParser()
        )
        answer = rag_chain.invoke({"chat_history": history, "context":context, "question":question })
        
        return answer

rag_chain = RAGPDFChain(llm=ChatOpenAI(model="gpt-4o-mini"), pdf="./data/AI_brief_2023ë…„_2ì›”í˜¸.pdf")
pdf_retriever = rag_chain.create_retriever()
answer = rag_chain.invoke(
    {
        "question": "AIê´€ë ¨ ìµœê·¼ êµ­ë‚´ì™¸ ì •ì±…ì€ ì–´ë•Œ?",
        "context": pdf_retriever,
        "chat_history": [],
    }
)
# pdf_retriever -> ë¬¸ì„œ ê²€ìƒ‰ê¸°
# rag_chain -> Generate 
```

í•˜ê¸°ëŠ” ê°€ì¥ ê°„ë‹¨í•˜ê²Œ êµ¬í˜„í•œ PDF RAG Chainì´ê³  ì´ì–´ì„œ Questionê³¼ Retrievalê°„ì˜ Relevence Checkë„ êµ¬í˜„í•´ë³´ê² ìŠµë‹ˆë‹¤.   
```python
"""ì§ˆë¬¸ê³¼ Retrievalê°„ì˜ ê´€ë ¨ì„±"""    
class QuestionRetrievalScore(BaseModel):
    score : str = Field(
        description="relevant or not relevant. Answer 'yes' if the question is relevant to the retrieved document else answer 'no'"
    )

class RelevanceChecker:
    """
    í•´ë‹¹ classëŠ” inputì— ëŒ€í•œ íƒ€ì…ì— ë”°ë¼ ê´€ë ¨ì„±ì„ í‰ê°€í•˜ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    ê´€ë ¨ì´ ìˆë‹¤ë©´ "yes", ì—†ë‹¤ë©´ "no"ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    í¬ê²Œ 3ê°€ì§€ì˜ íƒ€ì…ì— ê´€ë ¨í•œ ê´€ë ¨ì„± í‰ê°€í•©ë‹ˆë‹¤.
    (Question-Answer, Question-Retrieval, Answer-Retrieval)
    """
    
    def __init__(self, llm: object, types: str = "question-answer"):
        self.llm = llm
        self.types = types
    if self.types == "question-retrieval":
        model = self.llm.with_structured_output(QuestionRetrievalScore)
        template = """You are a grader assessing whether a retrieved document is relevant to the given question. \n
            Here is the question: \n\n {question} \n\n
            Here is the retrieved document: \n\n {context} \n
            If the document contains information that could help answer the question, grade it as relevant. \n
            Consider both semantic meaning and potential usefulness for answering the question. \n
            
            Give a binary score 'yes' or 'no' score to indicate whether the retrieved document is relevant to the question."""
        input_vars = ["question", "context"]
    else:
        raise ValueError(f"Invalid Types : {self.types}")
    prompt = PromptTemplate(template=template, input_variables=input_vars)
    
    chain = prompt | model
    return chain

question_retrieval_relevant = RelevanceChecker(  
        llm=ChatOpenAI(model="gpt-4o-mini", temperature=0), types="question-retrieval"  
    ).create()
# question_retrieval_relevant -> Question & Retrieval Relevence Checker
```

## Question Re-writer & Web Search Tool
ì´ë²ˆì—ëŠ” ë°©ê¸ˆì „ì— Retrieval Graderë¥¼ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤. ë§Œì•½ ì´ Retrieval Graderê°€ "No"ë¼ê³  ë‚´ë±‰ì„ ê²½ìš°, Queryë¥¼ ì¬ì‘ì„±ì„ ìˆ˜í–‰í•´ì•¼í•©ë‹ˆë‹¤. ì´ë¥¼ ìˆ˜í–‰í•˜ëŠ” Query Rewriteìš© LLMì„ êµ¬í˜„í•˜ê² ìŠµë‹ˆë‹¤.   
```python
# LLM ì´ˆê¸°í™”
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
# Query Rewriter í”„ë¡¬í”„íŠ¸ ì •ì˜(ììœ ë¡­ê²Œ ìˆ˜ì •ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤)
system = """You a question re-writer that converts an input question to a better version that is optimized \n 
for vectorstore retrieval. Look at the input and try to reason about the underlying semantic intent / meaning."""
# Query Rewriter í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±
re_write_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", system),
        (
            "human",
            "Here is the initial question: \n\n {question} \n Formulate an improved question.",
        ),
    ]
)
# Query Rewriter ìƒì„±
question_rewriter = re_write_prompt | llm | StrOutputParser()

print(f'[ì›ë³¸ ì§ˆë¬¸]: "{"AIê´€ë ¨ ìµœê·¼ êµ­ë‚´ì™¸ ì •ì±…ì€ ì–´ë•Œ?"}"')
print("[ì¿¼ë¦¬ ì¬ì‘ì„±]:", question_rewriter.invoke({"question": "AIê´€ë ¨ ìµœê·¼ êµ­ë‚´ì™¸ ì •ì±…ì€ ì–´ë•Œ?"}))
```
ì´ ì¬ì‘ì„±ëœ Questionì„ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ì‹œ Retrievalë¥¼ ìˆ˜í–‰í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ì§„í–‰ë  ê²ƒ ì…ë‹ˆë‹¤. ê·¸ëŸ¼ ì´ì–´ì„œ ë§Œì•½ ë¬¸ì„ ê²€ìƒ‰ê¸°ì— ê³„ì†í•´ì„œ íƒìƒ‰í•´ë„ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´, ì™¸ë¶€(ì›¹) ê²€ìƒ‰ì„ í†µí•´ ê°€ì ¸ì™€ì•¼í•˜ëŠ” ì´ë¥¼ ì´ìš©í•˜ëŠ” Toolì¸ Tavily Search toolì„ êµ¬í˜„í•˜ê² ìŠµë‹ˆë‹¤.   
```python
from langchain_core.documents import Document

web_search_tool = TavilySearchResults(
    max_results=3
    )
search_result = web_search_tool.invoke("AIê´€ë ¨ ìµœê·¼ êµ­ë‚´ì™¸ ì •ì±…ì€ ì–´ë•Œ?")
web_results_docs = [
    Document(
        page_content=web_result["content"],
        metadata={"source": web_result["url"]},
    )
    for web_result in search_result
]
print(web_results_docs)
```

## Node ìƒì„±
ì´ì œ ì´ë ‡ê²Œ í•„ìš”í•œ ê¸°ëŠ¥ë“¤ì„ ìˆ˜í–‰í•˜ëŠ” LLMë“¤ì„ ë‹¤ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤. ì´ì œ ì´ë“¤ì„ ë­‰ì³ì„œ LangGraphì˜ Nodeë¡œ êµ¬í˜„í•œ í›„, ì„œë¡œ Messageë¥¼ ì£¼ê³ ë°›ê²Œ í•˜ë©´ CRAGì˜ ì‹œìŠ¤í…œ êµ¬ì¶•ì´ ì™„ë£Œë©ë‹ˆë‹¤. ë”°ë¼ì„œ ìš°ì„  í•„ìš”í•œ STateë¥¼ ë¨¼ì € ì •ì˜í•´ë³´ê² ìŠµë‹ˆë‹¤. ìƒê°í•´ë³´ë©´, ìš°ì„  ì§ˆë¬¸ì„ ë‹¤ë¥¸ Nodeë¡œ ì „ë‹¬ì„ í•´ì•¼í•˜ë‹ˆ, **Questionì˜ ë³€ìˆ˜**ê°€ í•„ìš”í•˜ë©°, **Retreiveí•œ ë¬¸ì„œ**ë„ ì „ë‹¬ì„ í•´ì¤˜ì•¼í•©ë‹ˆë‹¤. ë˜, ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•œë‹¤í–ˆìœ¼ë‹ˆ **ì›¹ê²€ìƒ‰ì„ ìˆ˜í–‰í• ì§€ ë§ì§€ë¥¼ ë‹´ëŠ” ë³€ìˆ˜**ë„ í•„ìš”í•©ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ ìµœì¢… ìƒì„±í•œ ë‹µë³€ì´ ì˜ëª»ëœ ê²½ìš°, ë‹¤ì‹œ íšŒê·€í•˜ëŠ” ì‘ì—…ë„ í•„ìš”í•˜ë‹ˆ ê·¸ëŸ¼ ì´ **Generation**ì„ ë‹´ì„ ë³€ìˆ˜ë„ í•„ìš”í•  ê²ƒ ì…ë‹ˆë‹¤ ì´ 4ê°œë¥¼ ê°€ì§€ëŠ” GraphStateë¥¼ ì •ì˜í•´ë³´ê² ìŠµë‹ˆë‹¤.    
```python
# State ì •ì˜
class GraphState(TypedDict):
    question: Annotated[str, "The question to answer"]
    generation: Annotated[str, "The generation from the LLM"]
    web_search: Annotated[str, "Whether to add search"]
    documents: Annotated[List[str], "The documents retrieved"]
```

ìš°ì„  **PDF ê²€ìƒ‰ê¸°**ì™€ **ë‹µë³€ ìƒì„±** Nodeë¶€í„° êµ¬í˜„í•´ë³´ê² ìŠµë‹ˆë‹¤. PDF ê²€ìƒ‰ê¸°ëŠ” ì§ˆë¬¸ì„ ë°›ì•„ ì´ë¥¼ PDF Retrievalì— ë„˜ê²¨ì£¼ê³  ì´ì— ëŒ€í•œ ê²°ê³¼ë¥¼ GraphStateì˜ documents ë„£ì–´ ë„˜ê²¨ì£¼ë©´ ë©ë‹ˆë‹¤. ë‹µë³€ ìƒì„±ì€ ì´ì „ì— êµ¬í˜„í–ˆë˜ RAG Chainì„ ì´ìš©í•˜ë©´ ë˜ëŠ”ë°, RAG Chainì— Documentê²°ê³¼ì™€ ì§ˆë¬¸ì„ ê°™ì´ ë„˜ê²¨ì£¼ë©´ ê¸°ì¡´ RAGì™€ê°™ì´ ë‹µë³€ì„ ìƒì„±í•˜ê²Œ ë˜ëŠ”ë°, ì´ë¥¼ generationì— ë‹´ì•„ ë„˜ê²¨ì£¼ë©´ ë©ë‹ˆë‹¤.    
```python
# ë¬¸ì„œ ê²€ìƒ‰ ë…¸ë“œ
def retrieve(state: GraphState) -> GraphState:
    print("\n==== RETRIEVE ====\n")
    question = state["question"]

    # ë¬¸ì„œ ê²€ìƒ‰ ìˆ˜í–‰
    documents = pdf_retriever.invoke(question)
    return GraphState(documents=documents)

# ë‹µë³€ ìƒì„± ë…¸ë“œ
def generate(state: GraphState) -> GraphState:
    print("\n==== GENERATE ====\n")
    question = state["question"]
    documents = state["documents"]

    # RAGë¥¼ ì‚¬ìš©í•œ ë‹µë³€ ìƒì„±
    generation = rag_chain.invoke({"context": documents, "question": question})
    return GraphState(generation=generation)
```  

ì´ì–´ì„œ CRAGì˜ ê°€ì¥ ì¤‘ìš”í•œ **ìê¸° ë°˜ì„±** ë° **ìê¸° í‰ê°€**ì¸ ë¬¸ì„œ í‰ê°€ê¸°ë¥¼ êµ¬í˜„í•´ë³´ê² ìŠµë‹ˆë‹¤. ë¬¸ì„œ í‰ê°€ê¸°ì—ì„œëŠ” ì´ì „ì— ìƒì„±í–ˆë˜ Questionê³¼ Retrieveê°„ì˜ ê´€ë ¨ì„±ì„ í‰ê°€í•˜ëŠ” LLMì„ ì´ìš©í•˜ì—¬ í‰ê°€í•˜ë©´ë©ë‹ˆë‹¤. ì´ ë•Œ, PDF Retrieveì—ì„œ ê°€ì ¸ì˜¨ ë‹¤ì–‘í•œ ë¬¸ì„œë“¤ì— ëŒ€í•´ í•œ ë²ˆ ë” QA-Retrieve LLMìœ¼ë¡œ í‰ê°€í•˜ì—¬ ì •ë§ ì§ˆë¬¸ê³¼ ê´€ë ¨ì´ ìˆëŠ” ê²ƒë“¤ë§Œ documentë¡œ ë‚¨ê¸°ê³  ê´€ë ¨ì´ ì—†ë‹¤ê³  ì •ì˜í•œ ê²ƒë“¤ì€ filteringì„ ì‹œì¼œì¤ë‹ˆë‹¤. ë˜í•œ, ë§Œì•½ filtering í›„ ë¬¸ì„œì˜ ê°œìˆ˜ê°€ 0ê°œë¼ë©´ web Searchë¥¼ ì§„í–‰í•´ì•¼í•˜ëŠ”ë°, ì´ì— ëŒ€í•œ ì •ë³´ë„ "yes" or "no"ë¡œ GraphStateì˜ web_search ë³€ìˆ˜ì— ë‹´ì•„ í•¨ê»˜ ë„˜ê²¨ì£¼ë©´ ë©ë‹ˆë‹¤.    
```python
"""ë¬¸ì„œ ê´€ë ¨ì„± í‰ê°€"""
def grade_documents(state: GraphState) -> GraphState:
    print("==== [CHECK DOCUMENT RELEVANCE TO QUESTION] ====")
    question = state["question"]
    documents = state["documents"]
    
    # ê´€ë ¨ì„± ìˆëŠ” ë¬¸ì„œë§Œ ë‚¨ê¸°ê¸°
    relevence_documents = []
    for doc in documents:
        grade = question_retrieval_relevant.invoke({"question": question, "context": doc})
        score = grade.score
        # ê´€ë ¨ì„±ì´ ìˆë‹¤ë©´ ì¶”ê°€
        if score == "yes":
            print("---GRADE: DOCUMENT RELEVANT---")
            relevence_documents.append(doc)
        else:
            print("---GRADE: DOCUMENT NOT RELEVANT---")
            continue
    relevence_doc_count = len(relevence_documents)
    web_search = "Yes" if relevence_doc_count == 0 else "No"
    return GraphState(documents=relevence_documents, web_search=web_search)
``` 

ì´ì–´ì„œ ë§ˆì§€ë§‰ìœ¼ë¡œ ì¿¼ë¦¬ ì¬ì‘ì„± Nodeì™€ Web Search Nodeë¥¼ êµ¬í˜„í•´ë³´ê² ìŠµë‹ˆë‹¤. ì¿¼ë¦¬ ì¬ì‘ì„± NodeëŠ” ì´ì „ì— ë§Œë“¤ì—ˆë˜ Query Rewrite LLMì„ ì´ìš©í•˜ì—¬, ìˆ˜ì •ë˜ê¸° ì „ ì§ˆë¬¸ì„ í•´ë‹¹ LLMì˜ Inputìœ¼ë¡œ ë„£ì–´ì£¼ë©´, ì¬ìƒì„±ëœ ì§ˆì˜ë¥¼ ì–»ì–´ ë„˜ê²¨ì£¼ë©´ë©ë‹ˆë‹¤. Web Searchì˜ Node ë˜í•œ, í˜„ì¬ ì§ˆì˜ë¥¼ Tavily Search Toolì— ë„£ì–´ ì´ì˜ ê²°ê³¼ë¥¼ ë³€í™˜ë°›ì•„, í˜„ì¬ documentì— ì¶”ê°€í•˜ì—¬ documentë¥¼ ë„˜ê²¨ì£¼ë©´ ë©ë‹ˆë‹¤.   
```python
"""ì¿¼ë¦¬ ì¬ì‘ì„±"""
def rewrite_query(state: GraphState) -> GraphState:
    print("==== [TRANSFORM QUERY] ====")
    question = state["question"]
    rewrite_query = question_rewriter.invoke({"question":question})
    return GraphState(question=rewrite_query)

"""ì›¹ ê²€ìƒ‰ ë…¸ë“œ"""
def web_search_node(state: GraphState) -> GraphState:
    print("\n==== [WEB SEARCH] ====\n")
    question = state["question"]
    documents = state["documents"]

    # ì›¹ ê²€ìƒ‰ ìˆ˜í–‰
    docs = web_search_tool.invoke({"query": question})
    # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¬¸ì„œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    web_results = "\n".join([d["content"] for d in docs])
    web_results = Document(page_content=web_results)
    documents.append(web_results)

    return GraphState(documents=documents)
```

## Edge
ì´ë•Œê¹Œì§€ ì´ë²ˆ CRAGì‹œìŠ¤í…œì— í•„ìš”í•œ LangGraph Nodeë¥¼ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¼ ì´ì œ ì´ Nodeë“¤ì„ ì˜ ì´ì–´ì¤„ ìˆ˜ ìˆëŠ” Edgeì˜ êµ¬í˜„ì´ í•„ìš”í•©ë‹ˆë‹¤.    
ì—¬ê¸°ì„œ **ë¼ìš°íŒ…**ì„ ê³ ë ¤í•´ë³´ë©´, GraphStateì—ì„œ web_searchê°’ì´ "yes"ë¼ë©´, í˜„ì¬ documentê°€ 1ê°œë„ ì—†ë‹¤ëŠ” ì˜ë¯¸ê°€ ë˜ë¯€ë¡œ, ì§ˆì˜ìì²´ê°€ ì˜ëª»ë˜ì–´ ì´ ì§ˆì˜ë¥¼ ìˆ˜ì •í•´ì•¼í•  í•„ìš”ê°€ ìˆë‹¤ê³  ëŠê»´ì§‘ë‹ˆë‹¤. ë”°ë¼ì„œ, web_serachê°’ì´ "yes"ë¼ë©´, ë‹¤ì‹œ Query Rewrite Nodeë¡œ ì§„í–‰í•˜ë©´ ë˜ê³ , ë§Œì•½ "no"ë¼ë©´ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” generate Nodeë¡œ ë¸Œëœì¹˜ë¥¼ ì´ì–´ì£¼ë©´ ë  ê²ƒ ì…ë‹ˆë‹¤.    
```python
from typing_extensions import TypedDict, Annotated, Literal

def decide_to_generate(state: GraphState) -> Literal["query_rewrite", "generate"]:
    # í‰ê°€ëœ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒ ë‹¨ê³„ ê²°ì •
    print("==== [ASSESS GRADED DOCUMENTS] ====")
    # ì›¹ ê²€ìƒ‰ í•„ìš” ì—¬ë¶€
    web_search = state["web_search"]

    if web_search == "Yes":
        # ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ì •ë³´ ë³´ê°•ì´ í•„ìš”í•œ ê²½ìš°
        print(
            "==== [DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, QUERY REWRITE] ===="
        )
        # ì¿¼ë¦¬ ì¬ì‘ì„± ë…¸ë“œë¡œ ë¼ìš°íŒ…
        return "query_rewrite"
    else:
        # ê´€ë ¨ ë¬¸ì„œê°€ ì¡´ì¬í•˜ë¯€ë¡œ ë‹µë³€ ìƒì„± ë‹¨ê³„(generate) ë¡œ ì§„í–‰
        print("==== [DECISION: GENERATE] ====")
        return "generate"
```

## Graph Compile
ì´ì œ ìµœì¢…ì ìœ¼ë¡œ ê° Node ë° Edgeë“¤ì„ ì´ìš©í•˜ì—¬ Graphë¥¼ êµ¬í˜„ í›„ ì»´íŒŒì¼ê¹Œì§€ ìˆ˜í–‰í•˜ê² ìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  ìµœì¢…ì ìœ¼ë¡œ ì–´ë–¤ í˜•íƒœë¥´ ì´ì–´ì§€ëŠ”ì§€ ì‹œê°í™”ë¡œ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤.   
```python
workflow = StateGraph(GraphState)

# Node ì¶”ê°€
workflow.add_node("pdf_retrieve", retrieve)
workflow.add_node("retrieve_evaluator", grade_documents)
workflow.add_node("query_rewrite", rewrite_query)
workflow.add_node("web_search_node", web_search_node)
workflow.add_node("generate", generate)

# Edge ì¶”ê°€
workflow.set_entry_point("pdf_retrieve")
workflow.add_edge("pdf_retrieve", "retrieve_evaluator")
workflow.add_conditional_edges(
    "retrieve_evaluator",
    decide_to_generate,
    {
        "query_rewrite": "query_rewrite",
        "generate": "generate"
    }
)
workflow.add_edge("query_rewrite", "web_search_node")
workflow.add_edge("web_search_node", "generate")
workflow.add_edge("generate", END)

app = workflow.compile(checkpointer=MemorySaver())
```

<div style="text-align : center;">
<img src="../../../assets/images/LangChain/2025-04-10-langgraph15/crag_graph.png" alt="crag_graph" style="zoom:150%;" />    
</div>    

<br>
ì´ì œ êµ¬ì¶•í•œ ì‹œìŠ¤í…œì˜ ê²°ê³¼ë¥¼ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤. í•˜ê¸°ì˜ ì½”ë“œë¥¼ ëŒë ¤ ë‚˜ì˜¨ ì¶œë ¥ë„ ë‚˜íƒ€ë‚´ë³´ê² ìŠµë‹ˆë‹¤.    
```python
from langchain_core.runnables import RunnableConfig
from stream import *

# stream function

inputs = GraphState(question="ì‚¼ì„± ê°€ìš°ìŠ¤ ì „ìì— ëŒ€í•´ ì•Œë ¤ì¤˜.")
# config ì„¤ì •(ì¬ê·€ ìµœëŒ€ íšŸìˆ˜, thread_id)
config = RunnableConfig(recursion_limit=20, configurable={"thread_id": "1"})

node_names = ["pdf_retrieve", "retrieve_evaluator", "query_rewrite", "web_search_node", "generate"]
streamer(app=app, inputs=inputs, config=config, node_names=node_names)
```

```bash
==== RETRIEVE ====

==== [CHECK DOCUMENT RELEVANCE TO QUESTION] ====

==================================================
ğŸ”„ Node: retrieve_evaluator ğŸ”„
- - - - - - - - - - - - - - - - - - - - - - - - - 
---GRADE: DOCUMENT NOT RELEVANT---
---GRADE: DOCUMENT NOT RELEVANT---
---GRADE: DOCUMENT NOT RELEVANT---
---GRADE: DOCUMENT NOT RELEVANT---
==== [ASSESS GRADED DOCUMENTS] ====
==== [DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, QUERY REWRITE] ====
==== [TRANSFORM QUERY] ====

==================================================
ğŸ”„ Node: query_rewrite ğŸ”„
- - - - - - - - - - - - - - - - - - - - - - - - - 
ì‚¼ì„± ê°€ìš°ìŠ¤ ì „ìì— ëŒ€í•œ ì •ë³´ì™€ ì£¼ìš” íŠ¹ì§•ì€ ë¬´ì—‡ì¸ê°€ìš”?
==== [WEB SEARCH] ====


==== GENERATE ====


==================================================
ğŸ”„ Node: generate ğŸ”„
- - - - - - - - - - - - - - - - - - - - - - - - - 
ì‚¼ì„± ê°€ìš°ìŠ¤ëŠ” ì‚¼ì„±ì „ìì˜ ë©€í‹°ëª¨ë‹¬ ìƒì„±í˜• ì¸ê³µì§€ëŠ¥ ëª¨ë¸ë¡œ, í´ë¼ìš°ë“œì™€ ì˜¨ë””ë°”ì´ìŠ¤ë¥¼ ìœ„í•œ ë‹¤ì–‘í•œ AI ëª¨ë¸ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©°, í…ìŠ¤íŠ¸, ì½”ë“œ, ì´ë¯¸ì§€ ìƒì„±ì„ ìœ„í•œ ì–¸ì–´ ëª¨ë¸, ì½”ë“œ ëª¨ë¸, ì´ë¯¸ì§€ ëª¨ë¸ ë“± 3ê°€ì§€ ì£¼ìš” ëª¨ë¸ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
```