---
title:  "11장 Mass-Storage Structure"
categories: OS
tag: [theory,OS]
toc: true
author_profile: false
sidebar:
    nav: "docs"
---

## HDD

### Disk Structor

HDD의 Structure   
![disk structure](https://github.com/drepion43/java1-1/assets/84303857/1082db89-d360-467c-ad82-7b1857b78ec6)   
![disk structure 2](https://github.com/drepion43/java1-1/assets/84303857/65c9e178-a214-4812-a035-f180f3079a50)   
sector : 데이터의 최소단위   
cylinder : spindler로부터 arm까지의 거리   
arm : 데이터를 읽는용   
바깥족 track일수록 sector 개수가 증가(더 많은 데이터 저장 가능)   
arm과 spindle 사이의 거리는 모두 동일(arm은 sync를 맞춰 움직이기 때문)    
**seek time : 요청하는 track까지 arm head를 움직이는 것 -> 원하는 track까지만 이동 -> 가장 큰 overhead 발생**   
**rotation delay : track이 회전해 원하는 데이터(sector)가 올떄까지의 시간**   
**transfer time : 데이터를 읽어 전송하는 시간**   
**rotation spindle(spindle를 rotation하는데 많은 전력이 소모됨) -> low power mode(standby mode) : spindle rotation을 멈춤**

### Access Time

**access time = seek time + rotation delay + data transfer time**    
seek time : arm head가 요청한 sector의 cylinder까지 움직이는 시간   
rotation delay : 원하는 sector가 올때까지 시간  
transfer time : 데이터를 읽어 전송하는데의 시간   
**가장 overhead가 큰 seek time의 최소화가 가장 중요(seek time은 seek distance와 유사)**   
![bandwidth2](https://github.com/drepion43/java1-1/assets/84303857/693977db-84bf-40be-9fd6-ef913e5f248a)   
**Disk band width = 실제 보낸 byte의 수 / 총 시간**   
![bandwidth](https://github.com/drepion43/java1-1/assets/84303857/2ea20f12-030a-4225-9c80-55344ca45b94)      

- Disk Scheduling

![disk scheduler](https://github.com/drepion43/java1-1/assets/84303857/74fae880-2f6c-420c-8cf8-20e5d11f37a3)

## SSD(Solid-State Disk)

**SSD : Flash Memory를 병럴로 연결하여 만든 것**   
![flash mem](https://github.com/drepion43/java1-1/assets/84303857/b719d74b-fdcb-44ea-b6ae-f7d33e41c455)   
움직이는 부품이 없어 HDD보다 안정적   
가격이 비쌈  
수명이 존재   
빠름(No seek time, No rotation delay)   
**read/write : page 단위, erase : block 단위 -> Garbage Collection의 이유**    
![erase시](https://github.com/drepion43/java1-1/assets/84303857/4fe07201-9a63-46b0-a2fa-10c224d6913d)      
**Grabage Collection : erase가 block 단위이니 live한 데이터를 다른 곳에 copy**   
![gc ex](https://github.com/drepion43/java1-1/assets/84303857/dfa4d087-b65b-48c5-a549-aba1c40dcc08)    
HDD와 SDD    
![hdd sdd](https://github.com/drepion43/java1-1/assets/84303857/b4015d75-6361-431d-ae0e-b1fd704564a8)     
**P/E cycle : SSD의 수명(하나의 cell에서 write를 특정횟수하면 못쓰는 경우), erase시 전력소모가 크고 메모리에 손상이 발생**   
특정 cell에만 계속하여 write하면 용량이 줄어듬   
**wear-leveling : cell을 골고루 write하여 수명 유지**   
![slc](https://github.com/drepion43/java1-1/assets/84303857/d040769e-0dda-4a4e-b7e8-a49d43dc46d1)   
**SLC, MLC, TLC, QLC : 우측으로 갈수록 P/E 수가 줄어 듬(write 횟수가 감소)**   
life time managment가 중요   

### DWPD(DriveWrites Per Day)

특정 용량을 하루에 몇번 쓸 수 있는지   
example) 500GB, lifetime : 5년, DWPD : 3   
하루에 1500GB씩 5년동안 사용 보장(500 X 3)   

### FTL(Flash Translation Layer)   

mapping table   
![ftl](https://github.com/drepion43/java1-1/assets/84303857/f08d4fe2-42a6-402f-936b-5e979b915fb3)   

## Disk Attachment

### Host-attched Storage

![DAS](https://github.com/drepion43/java1-1/assets/84303857/661c0841-539d-4aa5-8390-ee8c0e7162dc)   
Bus를 통해 연결   
시스템에 더 많은 장치에 액세스할 수 있도록 도와주는 역할(Port)   

### Network-Attached Storage(NAS)

![NAS](https://github.com/drepion43/java1-1/assets/84303857/ec58027b-d135-4638-abf7-0a837d4b18a0)   
TCP/IP Protocol로 사용   
Storage Server 이용   
네트워크 protocal 이용   
NAS가 Server라고 생각   
### Storage Area Network(SAN)

![SAN](https://github.com/drepion43/java1-1/assets/84303857/a5e073ac-64f5-4828-9973-6793d2859c82)   
storage는 host에게 dynamic하게 attach 가능   
Storage가 직접 SAN에 연결   
SAN은 FC(Five Channel), FC-AL(Five Channel- AL) 등 storage를 위한 interface 사용   
network protocol 대신 storage protocols 사용   

## Disk Scheduling

**Request Reordering -> For Seek Time Minimization**   

### FCFS(First Come First Serve)

![FCFS](https://github.com/drepion43/java1-1/assets/84303857/1ec570d4-f5eb-41ca-a560-54bd2e3a0649)   
온순서대로 수행   
**Cylinder NO**   

### SSTF(Short Seek Time First)

![SSTF](https://github.com/drepion43/java1-1/assets/84303857/51810b67-580b-436e-9513-507c84639bfe)   
현재 head위치에서 가까운 것부터 수행   
**Stravation이 발생 가능**   
**Optimal X**   

### SCAN(elevator Algorithm)   

![SCAN](https://github.com/drepion43/java1-1/assets/84303857/65dc755f-c820-4682-a179-18ffe9457111)   
양방향 direction, Cylinder의 끝까지 감   
SCAN하며 있는 것들부터 수행   
disk arm이 디스크의 한쪽 끝에서 다른쪽 끝으로 이동하며 가는 길목에 있는 모든 요청을 처리   
다른 한쪽 끝에 도달하면 역방향으로 이동하며 오는 길목에 있는 모든 요청을 처리하며 다시 반대쪽 끝으로 이동   
**Cylinder 위치에 따라 대기 시간이 다름**   

### C-SCAN(One Direction)   

![C-SCAN](https://github.com/drepion43/java1-1/assets/84303857/e2eb0650-9ec5-40b9-9592-70e96dfdc78f)   
SCAN과 비슷하지만 방향이 한 방향   
head가 한쪽 끝에서 다른쪽 끝으로 이동하며 가는 길목에 있는 모든 요청을 처리   
head끝까지 감   
다른쪽 끝에 도달했으면 요청을 처리하지 않고 곧바로 출발점으로 다시 이동   
**SCAN보다 균일한 시간대 보장**   

###  Look Algorithm(Does not go to 0 or 199)

![look algo](https://github.com/drepion43/java1-1/assets/84303857/1e0a31a8-007c-41dc-a33e-4f9628a5d6eb)   
양방향 direction   
SCAN이나 C-SCAN은 헤드가 디스크 끝에서 끝으로 이동   
head가 마지막 요청까지만 감   
**LOOK은 헤드가 진행 중이거나 그 방향에 더 이상 기다리는 요청이 없으면 head의 이동방향을 즉시 반대로 이동**   

### C-Look(Look + One Direction)   

![c-look](https://github.com/drepion43/java1-1/assets/84303857/b8d32aa3-1b79-489b-94a1-4c7410771bae)   
SCAN이나 C-SCAN은 헤드가 디스크 끝에서 끝으로 이동   
**C-LOOK은 헤드가 진행 중이거나 그 방향에 더 이상 기다리는 요청이 없으면 head의 이동방향을 즉시 반대로 이동**   
**C-LOOK** (C: circular)은 LOOK에서 곧바로 출발점으로 다시 이동   
**LOOK보다 균일한 대기 시간을 제공**   

## Disk Managment

### Disk Formatting

#### Low-Level formatting(Physical formatting)

디스크를 컨트롤러가 읽고 쓸 수 있도록 sector들로 나누는 과정, 즉, sector를 sector롤 구획화   
각 secotr는 header + 실제 data(보통 512 Bytes) + trailer로 구성   
header와 trailer는 sector number, ECC(Error-Correcting Code) 등의 정보가 저장되며 controller가 직접 접근 및 운영

#### Logical Formatting

**새로운 File system을 만드는 것**   
FAT, inode, free space 등의 구조 포함   

### Booting

ROM에 있는 small bootstrap loader의 실행   
sector 0(boot block)을 load하여 실행   
sector 0은 "full Bootstrap loader program" 임   
OS를 디스크에서 load하여 실행

### Swap Space

![swap space](https://github.com/drepion43/java1-1/assets/84303857/34cdced1-c15f-487b-b659-4f1634b3867c)   
swap out될시, 빈 페이지에 넣어 놓음   
Swap partiton 관리

1. 일반 file system에서 관리
2. Swap 영역을 별도의 managment를 통해 관리

보통 Linux는 Swap-Map manager로 관리 -> Swap Map으로 공유된 개수 표시   
## RAID(Redundant Array of Independent Disks)

**Data Loss시, recovery를 위해 중복하여 저장해둠**   

### Mirroring

![disk mirroring](https://github.com/garyexplains/examples/assets/84303857/0b900cd7-e525-4163-856f-76faf59b4e5c)   
그대로 복사   
용량이 2배로 증가   

### Parity

용량을 줄이는 방식   
XOR 연산 사용   
example)   
 ![parity](https://github.com/garyexplains/examples/assets/84303857/e1acb1c1-ab11-4a02-97e9-717551257199)     

**Parity의 경우 사용하지 않을 수 있는 Disk한개를 더 사용하기 때문에, 용량측면에서 Bad, Mirroring의 시간측면에서 Bad**   

### Stripping

Throughput을 높이기 위해 사용   
1개의 파일을 쪼개서 분산시켜 저장  
example)   
![disk stripping](https://github.com/garyexplains/examples/assets/84303857/7ae8d605-1ffe-4354-8baa-f3c52e99c10c)   
분산으로 진행되 처리율이 높음   
Block Size

1. fine - Bit-level Stripping : 거의 모든 Disk가 참여(bit로)
2. coarse - Block-level Stripping : 특정 Disk만 참여(block으로)   

#### Fault tolerance

고장이 나더라도 복구 가능   
MTTF(Mean Time To Failure) : 고장이 날때까지의 평균 수명시간   
example) single Disk의 MTTF : 100,000 hours   
100개의 Disk가 존재할 때, 100,000 / 100 = 1,000 hours -> 즉, Disk개수가 증가할수록 MTTF 또한 증가   
해결법 : Redunancy(Mirroring, Parity)   
MTTR(Mean Time To Repair) : failed disk를 고치는데 평균 시간   
Mean time to data loss of Mirroring : MTTF^2 / (2 X MTTR) = 100,00^2 / (2 X 10) = 57,000 years   

#### Data Loss

 ![disk recovery](https://github.com/garyexplains/examples/assets/84303857/5b9c36e1-fba7-44ce-9477-584261baefa5)   
Disk1이 fail시, spare Disk에서 recovery 가능   
**But, rebuilding(recovery) 도중에 Disk가 failed날시, Data Loss**   
즉, 복구 도중에 고장시 -> Data Loss

## RAID Structure

**RAID는 Stripping, fault-tolerance(mirroring, parity)에 따라 RAID를 분류** 

### RAID 0

stripping만 사용, 고장시 data loss, recovery 불가능

### RAID 1

mirroring만 사용, Stripping X   
1개의 disk failure까지만 recovery 가능

### RAID 2

memory-stype   
Reed-solomon coding -> error-correctin code   
https://en.wikipedia.org/wiki/Reed%E2%80%93Solomon_error_correction   
1개의 disk failure까지만 recovery 가능

### RAID 3

Stripping(bit-level) + Parity 함께 사용   
1개의 disk failure까지만 recovery 가능

### RAID 4

![raid 4](https://github.com/garyexplains/examples/assets/84303857/707c01d4-a533-4459-bcd3-df96530643d7)   
Stripping(block-level) + Parity   
1개의 disk failure까지만 recovery 가능

### RAID 5

![raid5](https://github.com/garyexplains/examples/assets/84303857/e45ea8e2-bbce-4fd8-b81f-752fd7548597)   
Stripping(Block-level) + Parity(distributed Parity)

### RAID 6

P + Q redundancy   
**2개의 disk failure시도 복구 가능**

### Small-write Problem

![samll-write problem](https://github.com/garyexplains/examples/assets/84303857/c3867e2f-767d-4653-b832-e1d0e9669370)   
A2를 업데이트해도, A1과 A3도 함께 읽어서 Parity 연산을 추가적으로 수행해야함   

1. A1, A3 read
2. parity 연산
3. parity bit update : overhead
